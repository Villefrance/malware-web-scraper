import scrapy
from scrapy.spidermiddlewares.httperror import HttpError


class CapeSpider(scrapy.Spider):
    name = "cape"
    allowed_domains = ["capesandbox.com"]
    url = 'https://capesandbox.com/analysis/{}/'
    start_id = "382783"

    def start_requests(self):
        yield scrapy.Request(self.url.format(int(self.start_id)), errback=self.get_errback)

        """
        path = './max_id.txt'
        if not os.path.isfile(path):
            sys.exit("Fatal error: 'max_id.txt' file not found. Please run cuckoo_start, or create this file manually "
                     "first.")

        with open('./max_id.txt', 'r') as max_id_file:
            max_id = max_id_file.read()
            if max_id.isdigit():
                self.start_id = max_id
            else:
                sys.exit("Fatal error: max_id.txt did not contain a valid ID.")

        for i in range(0,int(self.amount_to_fetch)):
            if self.start_id.isdigit():
                yield scrapy.Request(self.url.format(int(self.start_id)-i), errback=self.get_errback) #3967929-i
            else:
                sys.exit("Fatal error: start_id is empty or not a number.")
        """


    def parse(self, response):
        """
        self.state['items_count'] = self.state.get('items_count', 0) + 1
        self.state['start_id'] = self.start_id
        self.state['latest_url_crawled'] = response.request.url
        self.state['last_updated'] = datetime.now(timezone.utc)
        """

        md5 = response.css('table.table-striped.table-bordered tr:nth-child(4) td::text').get()

        yield {
            md5: response.request.url
        }

        for signature in response.css('#stadistics div div:nth-child(2) ul li::text').getall():
            clean_string = signature.strip().replace('\n', '')
            if not clean_string:
                continue
            yield {
                md5: clean_string
            }

    def get_errback(self, failure):
        self.logger.error(repr(failure))
        if failure.check(HttpError):
            response = failure.value.response
            if response.status == 404:
                self.logger.error('404 not found on %s', response.url)
                #self.state['not_found_errors'] = self.state.get('not_found_errors', 0) + 1

import json
from io import StringIO

import scrapy
from scrapy import FormRequest
from scrapy.shell import inspect_response
from scrapy_playwright.page import PageMethod


class CuckooSpider(scrapy.Spider):
    name = "cuckoo"
    allowed_domains = ["cuckoo.cert.ee"]
    url = 'https://cuckoo.cert.ee/analysis/{}/export/'

    def start_requests(self):
        for i in range(0,2):
            yield scrapy.Request(self.url.format(3967929-i))

    def parse(self, response):
        # self.state['items_count'] = self.state.get('items_count', 0) + 1
        # self.state['starting_id'] = response.css('table#recent tbody tr td strong::text').get()
        token = response.css("form input[name=csrfmiddlewaretoken]::attr(value)").extract_first()
        #print(token)

        # headers = {
        #
        # }

        # "Content-Type": "multipart/form-data",
        # "Content-Length": 280,
        # "Accept-Encoding": "gzip, deflate, br",
        # 			"Cache-Control": "no-cache",
        # 			"Connection": "keep-alive",
        # "Host": "cuckoo.cert.ee",
        # "Referer": "https://cuckoo.cert.ee/analysis/3967929/export/"

        formdata = {
            "csrfmiddlewaretoken": token,
            "dirs": "reports"
        }

        request = FormRequest(url=response.request.url,
                              formdata=formdata,
							  method='POST',
                              callback=self.parse_file)

        # request = FormRequest.from_response(response,
        #								formdata=formdata,
        #								#headers=headers,
        #								dont_click=True,
        #								#body=json.dumps(formdata),
        #								callback=self.parse_file)

        yield request

    def parse_file(self, response):
        id = response.request.url.split("/")[4]
        with open('{}.zip'.format(id), "wb") as zip_file:
            zip_file.write(response.body)

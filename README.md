# malware-web-scraper
This software was made as part of my Master's Thesis to gather data from two online instances of open-source sandboxes, Cuckoo and Cape.
## Gather data
## Step 0 - Setup
`python -m venv venv`
`source venv/bin/activate`
`pip install -r requirements.txt`
`playwright install`
May need:
`playwright install-deps`

### Scraping Cuckoo
#### Step 1 - CuckooStart spider
Optionally run `scrapy crawl cuckoo_start` once first to fetch the max/start id from (https://cuckoo.cert.ee/analysis/), and write it to a .txt file called `max_id_cuckoo.txt`. Alternatively, this file can be created manually. It should contain the id from which you want the crawler to start from (it will then decrement this id by 1 to fetch additional reports).
`cd malware`
`scrapy crawl cuckoo_start` --> `max_id_cuckoo.txt`

#### Step 2 - Cuckoo spider
`scrapy crawl cuckoo -a amount_to_fetch=1000 -s JOBDIR=~/malware-web-scraper/malware/crawls/cuckoo1 -s LOG_FILE=~/malware-web-scraper/malware/logs/cuckoo1.log`
The Cuckoo spider will read the `max_id_cuckoo.txt` file output by the CuckooStart spider above.
The argument `amount_to_fetch` tells the crawler how many analysis reports it should fetch.
Setting the `JOBDIR` makes it possible to skip already seen requests, so an analysis report is not crawled if it is already in the data set.
Setting the `LOG_FILE` is optional and will redirect the console output to a log file.
The Cuckoo spider will output one zip file containing a json file for each analysis report downloaded. A script is provided to unzip the json reports (see "Process data" below).

### Scraping Cape
#### Step 1 - CapeStart spider
Optionally run `scrapy crawl cape_start` once first to fetch the max/start id from (https://capesandbox.com/analysis/), and write it to a .txt file called `max_id_cape.txt`. Alternatively, this file can be created manually. It should contain the id from which you want the crawler to start from (it will then decrement this id by 1 to fetch additional reports).
`cd malware`
`scrapy crawl cape_start` --> `max_id_cape.txt`

#### Step 2 - Cape spider
`scrapy crawl cape -a amount_to_fetch=1000 -s JOBDIR=~/malware-web-scraper/malware/crawls/cape1 -s LOG_FILE=~/malware-web-scraper/malware/logs/cape1.log -o ~/malware-web-scraper/malware/reports/cape/json/cape1.json`
The Cape spider will read the `max_id_cape.txt` file output by the CapeStart spider above.
The argument `amount_to_fetch` tells the crawler how many analysis reports it should fetch.
Setting the `JOBDIR` makes it possible to skip already seen requests, so an analysis report is not crawled if it is already in the data set.
Setting the `LOG_FILE` is optional and will redirect the console output to a log file.
The Cape spider will extract data from the HTML and output a line for each sample in the json output file defined with `-o`. To make it possible to extract other data at a later point in time, without having to download the same pages from the server again, the HTML file will also be saved (for use with the CapeLocal spider, see below).


#### Optional: CapeLocal spider
`scrapy crawl cape_local -a input_dir=~/malware-web-scraper/malware/reports/cape/html/ -o ~/malware-web-scraper/malware/reports/cape/json/cape_local1.json -s LOG_FILE=~/malware-web-scraper/malware/logs/cape_local1.log`
The Cape local spider enables parsing the downloaded HTML from capesandbox.com again. This can be useful if other data needs to be extracted, or an error was made in the first run. It works similarly to the normal Cape spider above, just with the difference that it runs on local files (and therefore also run faster).

---

## Utility scripts - Process data
## Step 0 - Install required python modules
`source venv/bin/activate`
`pip install -r requirements.txt`


## unzip_cuckoo_reports.py
Script to unzip the downloaded .zip files from Cuckoo Sandbox.
Paths should be absolute to avoid issues.
Usage:
`python3 unzip_cuckoo_reports.py <input_dir> <output_dir>`

Example:
`python3 unzip_cuckoo_reports.py /Users/fyxe/IdeaProjects/malware-web-scraper/malware/reports/cuckoo/zip/ /Users/fyxe/IdeaProjects/malware-web-scraper/malware/reports/cuckoo/json/`

## convert_cuckoo_json_to_single_file.py
A script to convert the separate json files generated by the unzip_cuckoo_reports.py script above, to a single combined json file, containing the same information as the CAPE json file - this makes the size much smaller and the data more easily comparable.

Usage:
`python3 convert_cuckoo_json_to_single_file.py <cuckoo_json_input_dir> <output_filename>`

Example:
`python3 convert_cuckoo_json_to_single_file.py /Users/fyxe/IdeaProjects/malware-web-scraper/malware/reports/cuckoo/json /Users/fyxe/IdeaProjects/malware-web-scraper/malware/reports/cuckoo/cuckoo_combined.json`

## check_same_hashes.py
Script to find the hashes that are present in both the cuckoo and cape data set. Matches will be written to a new json file that can be used for further analysis.

Usage:
`python3 check_same_hash.py <cape_input_filename> <cuckoo_input_filename> <output_filename>`

Example:
`python3 check_same_hash.py /Users/fyxe/IdeaProjects/malware-web-scraper/malware/reports/cape/json/cape1.json /Users/fyxe/IdeaProjects/malware-web-scraper/malware/reports/cuckoo/cuckoo_combined.json /Users/fyxe/IdeaProjects/malware-web-scraper/malware/analysis/matching_hashes.json`

## remove_duplicates.py
Script to find samples with more than one analysis report from the same sandbox (based on each sample’s sha256 hash). If more than one report is found for a sample, the newest report will be kept and the older ones discarded. The resulting .json file can be used for further analysis.

Usage:
`python3 remove_duplicates.py <input_filename> <output_filename>`

Example:
`python3 remove_duplicates.py ~/IdeaProjects/malware-web-scraper/malware/reports/cuckoo/cuckoo_combined.json ~/IdeaProjects/malware-web-scraper/malware/analysis/cuckoo_combined_no_duplicates.json`

## Rest of the utility
The rest of the utility scripts was used specifically to calculate some of the results for my Master's Thesis, and may therefore not be useful to others. 


## Disclaimer
THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
